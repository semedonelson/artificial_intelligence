# -*- coding: utf-8 -*-
"""convolutional_neural_network.ipynb

Automatically generated by Colaboratory.

modules needed:
pip install tensorflow
pip install kera
pip install pillow

Original file is located at
    https://colab.research.google.com/drive/1-nUptPfjnjedkWeTogOxFctMLEqmH14N

# Convolutional Neural Network

### Importing the libraries
"""

import tensorflow as tf
# class ImageDataGenerator allow us to process images
from keras.preprocessing.image import ImageDataGenerator
import numpy as np
from keras.preprocessing import image

tf.__version__

"""## Part 1 - Data Preprocessing

### Preprocessing the Training set
"""

# we applied transformation on the training set dataset to avoid overfitting
# Overfitting means that we'll high accuracy on training data (+-98%) and low accuracy on test set (+-80%)
# these transformations are some simple geometrical transformation, zoons or rotations on the data
# transformations is for instance transvections to shift some pixels
# https://keras.io/ja/preprocessing/image/
# rescale is to applied feature scalling to our data, it will devide every pixel values to 255. The pixel values will be between 0 and 1
train_datagen = ImageDataGenerator(rescale=1. / 255,
                                   shear_range=0.2,
                                   zoom_range=0.2,
                                   horizontal_flip=True)
# now we must connet our train_datagen to our training_set
training_set = train_datagen.flow_from_directory('dataset/training_set',
                                                 target_size=(64, 64),
                                                 batch_size=32,
                                                 class_mode='binary')
# class_mode can be one of "categorical", "binary", "sparse", "input", or "None".

"""### Preprocessing the Test set"""

# on the test set the only process applied is the scalling
test_datagen = ImageDataGenerator(rescale=1. / 255)
test_set = test_datagen.flow_from_directory('dataset/test_set',
                                            target_size=(64, 64),
                                            batch_size=32,
                                            class_mode='binary')

"""## Part 2 - Building the CNN

### Initialising the CNN
"""

# same class used on ANN because CNN is also a type of ANN
cnn = tf.keras.models.Sequential()

"""### Step 1 - Convolution"""

# add first convolution layer (Conv2D) https://keras.io/api/layers/convolution_layers/convolution2d/ filters -
# Integer, the dimensionality of the output space (i.e. the number of output filters in the convolution) kernel_size
# - dimension (3x3) input_shape - define the image dimension and 3 because we are working with color image (RBG).
# Only applied on the input layer
cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[64, 64, 3]))

"""### Step 2 - Pooling"""

# add pooling layers to our CNN (in this case max pooling)
# means that we take the max pixel value on a certain group of pixels
# pool_size - 2x2 pixels and take their max value
# strides - how many pixel we shit to the right after applying max pool on first group of pixels
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))

"""### Adding a second convolutional layer"""

# add another convolutional layer, this time without the input_shape
cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))
# add max pooling layer to the added new convolutional layer
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))

"""### Step 3 - Flattening"""

# flattening the result of all convolutional and pooling into a one dimensional array.
# this array will be used as a input to a fully connected ANN
cnn.add(tf.keras.layers.Flatten())

"""### Step 4 - Full Connection"""

# units - number of hidden neurons 
# until the output layer is recomended to use relu as a activation function
cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))

"""### Step 5 - Output Layer"""

# as we are doing bynary classification we only need 1 neuron as a output. on the output, we use sigmoid as
# activation function on a binary classification else we use softmax for multiclass classification
cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))

"""## Part 3 - Training the CNN

### Compiling the CNN
"""

cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

"""### Training the CNN on the Training set and evaluating it on the Test set"""

# as long we are evaluating it on the test set, we must specified the validation_data wich is out test_set
cnn.fit(x=training_set, validation_data=test_set, epochs=25)

"""## Part 4 - Making a single prediction"""

# load our test image
test_image = image.load_img('dataset/single_prediction/cat_or_dog_1.jpg', target_size=(64, 64))
# convert the PIL image format to an array
test_image = image.img_to_array(test_image)
# add extra dimension to the image because out model was training on 32 batches of images
test_image = np.expand_dims(test_image, axis=0)
# perform the prediction (result = 1 or 0)
result = cnn.predict(test_image)
training_set.class_indices
# result[batch][element]
if result[0][0] == 1:
    prediction = 'dog'
else:
    prediction = 'cat'

print(prediction)
